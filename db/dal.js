#!/usr/bin/node
const logger = require('logger').get('dal');
const db = require('./db-connect');
const Long = require('long');
// TODO move these to config file or something
// epoch comes from https://discord.com/developers/docs/reference#snowflakes-snowflake-id-format-structure-left-to-right
const epoch = 1420070400000; // ms between 1970 and 2015
// bucket size represents ten days, per https://blog.discord.com/how-discord-stores-billions-of-messages-7fa6ec7ee4c7
const bucket_size = 1000 * 60 * 60 * 24 * 10; // ms per ten days
const snowmachine = new (require('snowflake-generator'))(epoch);
// represents the Discord Epoch, in 2015 or something
const discriminator_cap = 10000; // permit #0000 to #9999

const hasher = require('argon2');
const hash_options = {
	type: hasher.argon2id
};

const getBucket = (timestamp, errors = []) => {
	timestamp = coerceToLong(timestamp, errors);
	return Math.round((timestamp.shiftRightUnsigned(22) - 0 + epoch) / bucket_size);
};

// cassandra-driver:
// https://docs.datastax.com/en/developer/nodejs-driver/4.6/api/class.Client/

// TODO: enforce foreign key constraints

class Schema {
	constructor(name, keys = [], requireds = [], nullables = [], immutables = [], automatics = [], update_keys = [], typeSamples = {}, validators = [], permitNulls = false) {
		// e.g. 'guilds', 'channels_by_guild'
		// this is used as a table name for generating CQL
		this.name = name;
		// list of all column names
		this.keys = keys;
		// list of all columns who must be specified in any query:
		// both new records and updates to existing records _must_
		// have these keys. this is NOT an exhaustive list of all keys
		// that must never be left null. see nullables
		this.requireds = requireds;
		// list of all columns whose values are not mandatory (may be
		// omitted when the record is created)
		// this list takes part in automatic validation
		this.nullables = nullables;
		// list of all columns whose values are immutable once a row has
		// been written
		this.immutables = immutables;
		// list of all columns whose values are generated by code in this
		// file, rather than supplied by the user/other areas of the
		// application
		// (e.g. snowflakes are generated here when a record is created)
		this.automatics = automatics;
		// list of all columns used to identify rows to be updated
		// used by this.getUpdateStmt
		this.update_keys = update_keys;
		// collection of type samples for type validation
		this.typeSamples = typeSamples;
		// list of functions that validate a schema
		// each function takes an object (proposed record) and a boolean
		// (whether to treat the object as a new record or a set of updates)
		// if the object is treated as a set of updates, some fields may be
		// omitted, whereas a new record must have all fields specified
		// (unless the record is okay with leaving things empty)
		// each function returns an array of zero or more strings, each of
		// which describes an error with the input
		this.validators = validators;
		// whether or not to ever permit a key to have a null value
		this.permitNulls = permitNulls;

		this.validators.push(Schema.getCheckForMissingKeys(this));
		this.validators.push(Schema.getCheckForTypeErrors(this));
	}

	trim(obj) {
		const out = {};
		this.keys.forEach(key => {out[key] = obj[key];});
		Object.keys(out).forEach(key => {
			if (out[key] === undefined) delete out[key];
		});
		return out;
	}

	validate(obj, isUpdate = false) {
		const errors = [];
		this.validators.forEach(v => {
			errors.push(...v(obj, isUpdate));
		});
		return errors;
	}

	get updatables() {
		return this.keys.filter(key => !this.immutables.includes(key));
	}

	getInsertStmt(record) {
		record = this.trim(record);
		const errors = this.validate(record, false);
		if (errors.length) {
			throw errors;
		}

		const columns = Object.keys(record);
		const params = columns.map(key => record[key]);

		const column_string = columns.join(', ');
		const value_string = columns.map(x => '?').join(', ');

		return [
			`INSERT INTO ${this.name} (${column_string}) VALUES (${value_string});`
			, params
			, { prepare: true }
		];
	}

	getSelectStmt(criteria = '', params = []) {
		return [
			`SELECT * FROM ${this.name} ${criteria};`
			, params
			, { prepare: true }
		];
	}

	getUpdateStmt(changes) {
		changes = this.trim(changes);
		const errors = this.validate(changes, true);
		if (errors.length) {
			throw errors;
		}

		const columns = [];
		const update_keys = [];
		const params = [];
		Object.keys(changes).forEach(key => {
			if (this.immutables.includes(key))
				update_keys.push(key);
			else
				columns.push(key);
		});
		for (let key of columns) params.push(changes[key]);
		for (let key of update_keys) params.push(changes[key]);
		const column_string = columns.map(c => c + ' = ?').join(', ');
		const key_string = update_keys.map(c => c + ' = ?').join(' AND ');

		return [
			`UPDATE ${this.name} SET ${column_string} WHERE ${key_string};`
			, params
			, { prepare: true }
		];
	}

	getDeleteStmt(criteria) {
		criteria = this.trim(criteria);
		const errors = [];
		// forbid deleting based on anything mutable
		for (let key of Object.keys(criteria))
			if (this.updatables.includes(key))
				errors.push(`DELETE criteria may only be immutable columns (${this.immutables.join(', ')}), but ${key} was supplied`);
		if (errors.length) {
			throw errors;
		}

		// deletion criteria are OK, so carry on
		const columns = Object.keys(criteria);
		const params = columns.map(key => criteria[key]);

		const criteria_string = columns.map(c => c + ' = ?').join(' AND ');
		return [
			`DELETE FROM ${this.name} WHERE ${criteria_string};`
			, params
			, { prepare: true }
		];
	}

	static getCheckForMissingKeys(_this) {
		return (obj, isUpdate) => {
			const errors = [];
			if (isUpdate) {
				// check that all requireds are supplied
				for (let key of _this.requireds)
					if (obj[key] === undefined) errors.push(`Key ${key} is required for an update, but was not supplied`);
				// check that all supplied keys are not null
				for (let key of _this.keys)
					if (!_this.permitNulls && obj[key] === null) errors.push(`Key ${key} is required for an update, but null was supplied`);
				// check that at least one mutable key is supplied
				// i.e., make sure we're actually updating something
				if (_this.keys
					.filter(key => !_this.immutables.includes(key))
					.filter(key => obj[key] !== undefined)
					.length === 0)
					errors.push(`At least one key besides [${_this.immutables.join(', ')}] must be supplied for an update, but none were`);
				/*
				else console.log(_this.keys
					.filter(key => !_this.immutables.includes(key))
					.filter(key => obj[key] !== undefined)
				);
				 */
			} else {
				// ensure that all keys that aren't optional are defined,
				// and also that all keys that are defined aren't null if nulls are not permitted
				// i.e., if !permitNulls, then an optional key can be anything but null
				for (let key of _this.keys)
					if (obj[key] === undefined && !_this.nullables.includes(key)) errors.push(`Key ${key} is required for a new record, but was not supplied`);
				else if (!_this.permitNulls && obj[key] === null) errors.push(`Key ${key} must not be null, but null was supplied`);
			}
			return errors;
		}
	}

	static getCheckForTypeErrors(_this) {
		return (obj, isUpdate) => {
			const errors = [];
			for (let key of Object.keys(_this.typeSamples))
				if (obj[key] !== undefined
					&& obj[key] !== null
					&& obj[key].constructor.name !== _this.typeSamples[key].constructor.name)
					errors.push(`Key ${key} must be of type ${_this.typeSamples[key].constructor.name}, but the supplied value ${obj[key]} is of type ${obj[key].constructor.name}`);
			return errors;
		}
	}

}

// takes data from database and converts anything necessary before shipping data to users
// e.g. convert snowflakes from Long to string
const convertTypesForDistribution = (row) => {
	const out = {};
	for (let key of Object.keys(row))
		if (row[key] !== undefined && row[key] !== null)
			switch (row[key].constructor.name) {
				case 'Long': out[key] = row[key].toString(); break;
				default: out[key] = row[key];
			}
	else out[key] = row[key];
	return out;
};

// oh no, what have i done
// name, keys, requireds, nullables, immutables, automatics, update keys, type samples, validators, permit nulls
const schemas = {
	guilds: new Schema('guilds'
		, ['guild_id', 'name', 'icon_id'] // keys
		, ['guild_id'] // requireds
		, [] // nullables
		, ['guild_id'] // immutables
		, ['guild_id'] // automatics
		, ['guild_id'] // update keys
		, { // type samples
			'guild_id': new Long()
			, 'name': ''
			, 'icon_id': new Long()
		})
	, channels_by_guild: new Schema('channels_by_guild'
		, ['guild_id', 'position', 'channel_id', 'name'] // keys
		, ['guild_id', 'channel_id'] // requireds // i just added channel_id, that might be wrong
		, [] // nullables
		, ['guild_id', 'channel_id'] // immutables
		, ['channel_id'] // automatics
		, ['guild_id', 'channel_id'] // update keys
		, { // type samples
			'guild_id': new Long()
			, 'position': 0
			, 'channel_id': new Long()
			, 'name': ''
		}
		, [ // validators
			(record, isUpdate) => {return ((isUpdate && record.name === undefined) || (/^[a-z-]{1,64}$/.test(record.name) && /^[a-z]/.test(record.name) && /[a-z]$/.test(record.name) && !(/--/.test(record.name))))? [] : [`Channel name must be composed only of lowercase a-z and hyphens, with no more than one consecutive hyphen, starting and ending with a letter, but ${record.name} was supplied`]}
		])
	, messages_by_channel_bucket: new Schema('messages_by_channel_bucket'
		, ['channel_id', 'bucket', 'message_id', 'author_id', 'body'] // keys
		, ['channel_id', 'bucket', 'message_id'] // requireds
		, [] // nullables
		, ['channel_id', 'bucket', 'message_id', 'author_id'] // immutables
		, ['channel_id', 'bucket', 'message_id'] // automatics
		, ['channel_id', 'bucket', 'message_id'] // update keys
		, { // type samples
			'channel_id': new Long()
			, 'bucket': 0
			, 'message_id': new Long()
			, 'author_id': new Long()
			, 'body': ''
		}
		, [ // validators
		])
	, users: new Schema('users'
		, ['user_id', 'name', 'discriminator', 'password', 'email', 'icon_id'] // keys
		, ['user_id'] // requireds
		, [] // nullables
		, ['user_id', 'email'] // immutables
		, ['user_id', 'discriminator'] // automatics
		, ['user_id'] // update keys
		, { // type samples
			'user_id': new Long()
			, 'name': ''
			, 'discriminator': 0
			, 'password': ''
			, 'email': ''
			, 'icon_id': new Long()
		}
		, [ // validators
		])
	, icons: new Schema('icons'
		, ['icon_id', 'url'] // keys
		, ['icon_id'] // requireds
		, [] // nullables
		, ['icon_id', 'url'] // immutables
		, ['icon_id'] // automatics
		, [] // update keys
		, { // type samples
			'icon_id': new Long()
			, 'url': ''
		}
		, [ // validators
			(obj, isUpdate) => { return isUpdate ? ['An attempt was made to update an icon, but this operation is not permitted'] : []; }
		])
};

// adds things like 'guild_id < ?' to the list of constraints supplied
// also adds errors if appropriate
const addSnowflakeConstraint = (key, constraint_string, options, constraints, params, errors, required = false) => {
	if (options[key] === undefined) {
		if (required)
			errors.push(`'${key}' must be a snowflake (either as a string or a Long), but ${options[key]} was supplied`);
		return;
	}
	if (options[key] === null) {
		errors.push(`'${key}' must be a snowflake (either as a string or a Long), but ${options[key]} was supplied`);
		return;
	}
	constraints.push(`${constraint_string} ?`);
	switch (options[key].constructor.name) {
		case 'String':
		case 'Long':
			params.push(coerceToLong(options[key], errors));
			break;
		default:
			errors.push(`'${key}' must be a snowflake (either as a string or a Long), but ${options[key]} of type ${options[key].constructor.name} was supplied`);
	}
};

const generateResultLimit = (limit, params, errors, required = false) => {
	if (limit === undefined) {
		if (required)
			errors.push(`'limit' search filter must be supplied, but was not`);
		return '';
	}
	if (limit === null) {
		errors.push(`'limit' search filter must be a Number, but ${limit} was supplied`);
		return '';
	}
	if (limit.constructor.name !== 'Number')
		errors.push(`'limit' search filter must be a Number, but ${limit} of type ${limit.constructor.name} was supplied`);
	else if (limit < 1)
		errors.push(`'limit' search filter must be a positive integer, but ${limit} was supplied`);
	else {
		params.push(limit);
		return ' LIMIT ?';
	}
};

const coerceToLong = (x, errors = []) => { // error list may be omitted; if it doesn't look like a snowflake then we return null
	if (x === undefined || x === null) {
		errors.push(`A value representing a snowflake was expected, but ${x} was supplied`);
		return null;
	}
	if (x.constructor.name === 'Long') return x;
	if (x.constructor.name === 'String') {
		const out = Long.fromString(x);
		if (out == 0) {
			errors.push(`The string '${x}' does not appear to represent a snowflake, but a snowflake was required`);
			return null;
		}
		return out;
	}
	if (x.constructor.name === 'Number') {
		errors.push(`Most snowflakes used in this application are too large to store as 64-bit floats; therefore, to prevent data errors, the numeric value ${x} was rejected during snowflake parsing. Please pass in a string or Long representing the snowflake`);
	}
	return null;
};

/*
 ** guidelines for designing these methods
 ** 
 **  - all crud operations are async and may throw an array of strings that describe errors
 **   - as many errors as possible/helpful should be thrown at once
 **   - all methods should start with a type-checking block
 **  - all snowflakes should be acceptable as either strings or Longs
 **  - all snowflakes should be returned as strings
 **  - optional keys or parameters that are undefined should be ignored
 **  - optional keys or parameters with otherwise illegal values (including null) should throw errors
 **  - required keys or parameters with illegal values (including undefined and null) should throw errors
 **
 **  - create takes only mandatory parameters, no options object
 **   - returns the created record
 **  - read takes mandatory parameters and an options object
 **   - returns an array of records
 **  - update takes mandatory parameters and an options object
 **   - returns undefined
 **  - delete takes only mandatory parameters, no options object
 **   - returns undefined
 **
 */

/*************************************************************************
 * guilds
 */
// returns description of guild, or throws
const createGuild = async (name, icon_snowflake) => {
	const errors = [];
	if (name === undefined || name === null)
		errors.push(`A name must be passed, but ${name} was supplied`);
	if (icon_snowflake === undefined || icon_snowflake === null)
		errors.push(`An icon snowflake must be passed, but ${icon_snowflake} was supplied`);
	else icon_snowflake = coerceToLong(icon_snowflake, errors);
	if (errors.length) {
		throw errors;
	}

	const record = {
		guild_id: coerceToLong(snowmachine.generate().snowflake)
		, name
		, icon_id: icon_snowflake
	};

	return db.execute(...schemas.guilds.getInsertStmt(record))
		.then(() => convertTypesForDistribution(record))
	;
};

// returns list of guild descriptions, or throws
const getGuilds = async (options = {
	guild_id: undefined
	, limit: undefined
}) => {
	const keys = Object.keys(options);
	const constraints = [];
	let limit = '';
	const params = [];
	const errors = [];

	// catch passing other junk as the options
	if (options === null || options.constructor.name !== 'Object') 
		errors.push(`An optional object containing filtering keys was expected, but ${options} was supplied`);

	addSnowflakeConstraint('guild_id', 'guild_id =', options, constraints, params, errors);
	limit = generateResultLimit(options.limit, params, errors);

	if (errors.length) {
		throw errors;
	}

	let opt_string = '';
	if (constraints.length) opt_string = 'WHERE ';
	opt_string += constraints.join(' AND ');
	opt_string += limit;

	return db.execute(...schemas.guilds.getSelectStmt(opt_string, params))
		.then(res => res.rows)
		.then(rows => rows.map(convertTypesForDistribution))
	;
};

// returns or throws
// FIXME this is currently an expensive operation, with three queries total
// try to reduce this, eh?
// ok, it's just two now---got rid of the last fetch; returns undefined on success
const updateGuild = async (guild_snowflake, changes) => {
	const errors = [];

	if (guild_snowflake === undefined || guild_snowflake === null)
		errors.push(`A guild snowflake must be passed, but ${guild_snowflake} was supplied`);
	else guild_snowflake = coerceToLong(guild_snowflake, errors);
	if (changes === undefined || changes === null || changes.constructor.name !== 'Object' || Object.keys(changes).length < 1)
		errors.push(`An object describing changes to be made must be passed, but ${changes} was supplied`);
	if (changes && changes.icon_id !== undefined)
		changes.icon_id = coerceToLong(changes.icon_id, errors);

	if (errors.length) {
		throw errors;
	}

	return getGuilds({guild_id: guild_snowflake})
		.then(rows => rows.length > 0)
		.then(recordExists => {
			if (recordExists)
				return db.execute(...schemas.guilds.getUpdateStmt(Object.assign({}, {guild_id: guild_snowflake}, changes)))
					.then(() => {})
			;
			else
				throw [`Only existing guilds may be updated, but no guild with id ${guild_snowflake} was found`];
		});
};

// returns or throws
const deleteGuild = async (guild_snowflake) => {
	const errors = [];
	if (guild_snowflake === undefined || guild_snowflake === null)
		errors.push(`A guild snowflake must be passed, but ${guild_snowflake} was supplied`);
	else guild_snowflake = coerceToLong(guild_snowflake, errors);
	if (errors.length) {
		throw errors;
	}

	return db.execute(...schemas.guilds.getDeleteStmt({
		guild_id: guild_snowflake
	})).then(() => {});
};

/*************************************************************************
 * channels_by_guild
 */
// returns description of channel, or throws
const createChannel = async (guild_snowflake, name, position = -1) => {
	const errors = [];
	if (guild_snowflake === undefined || guild_snowflake === null)
		errors.push(`A guild snowflake must be passed, but ${guild_snowflake} was supplied`);
	else guild_snowflake = coerceToLong(guild_snowflake, errors);
	if (name === undefined || name === null)
		errors.push(`A name must be passed, but ${name} was supplied`);
	if (position === null || position.constructor.name !== 'Number')
		errors.push(`An optional position may be passed, but ${position} was supplied`);
	if (errors.length) {
		throw errors;
	}

	if (!(position > 0)) { // this handles strings and bad guys lmao end me // this shouldn't matter; catch type errors above
		// by default, append the channel to the end of the guild
		position = await getChannels(guild_snowflake).then(rows => rows.length);
		console.log('using position ' + position);
	} else position = position - 0; // coerce number type

	const record = {
		guild_id: guild_snowflake
		, channel_id: coerceToLong(snowmachine.generate().snowflake)
		, name
		, position
	};

	return db.execute(...schemas.channels_by_guild.getInsertStmt(record))
		.then(() => convertTypesForDistribution(record));
};

const addChannelToGuild = async (guild_snowflake, channel_snowflake, name, position = -1) => {
	const errors = [];
	if (guild_snowflake === undefined || guild_snowflake === null)
		errors.push(`A guild snowflake must be passed, but ${guild_snowflake} was supplied`);
	else guild_snowflake = coerceToLong(guild_snowflake, errors);
	if (channel_snowflake === undefined || channel_snowflake === null)
		errors.push(`A channel snowflake must be passed, but ${channel_snowflake} was supplied`);
	else channel_snowflake = coerceToLong(channel_snowflake, errors);
	if (name === undefined || name === null)
		errors.push(`A name must be passed, but ${name} was supplied`);
	if (position === null || position.constructor.name !== 'Number')
		errors.push(`An optional position may be passed, but ${position} was supplied`);
	if (errors.length) {
		throw errors;
	}

	if (!(position > 0)) { // this handles strings and bad guys lmao end me // this shouldn't matter; catch type errors above
		// by default, append the channel to the end of the guild
		position = await getChannels(guild_snowflake).then(rows => rows.length);
		console.log('using position ' + position);
	} else position = position - 0; // coerce number type

	const record = {
		guild_id: guild_snowflake
		, channel_id: channel_snowflake
		, name
		, position
	};

	return db.execute(...schemas.channels_by_guild.getInsertStmt(record))
		.then(() => convertTypesForDistribution(record));
};

// TODO consider removing before and after; they're kinda useless, innit?
// returns list of channel descriptions, or throws
const getChannels = async (guild_snowflake, options = {
	before: undefined
	, after: undefined
	, channel_id: undefined
	, limit: undefined
}) => {
	const keys = Object.keys(options);
	const constraints = [];
	let limit = '';
	const params = [];
	const errors = [];

	// catch passing other junk as the options
	if (options === null || options.constructor.name !== 'Object') 
		errors.push(`An optional object containing filtering keys was expected, but ${options} was supplied`);

	// mandatory; this is the partition key
	addSnowflakeConstraint('guild_snowflake', 'guild_id =', {guild_snowflake}, constraints, params, errors, true); // true: this is required and will fail if not provided

	// optional constraints
	addSnowflakeConstraint('before'    , 'channel_id <', options, constraints, params, errors);
	addSnowflakeConstraint('after'     , 'channel_id >', options, constraints, params, errors);
	addSnowflakeConstraint('channel_id', 'channel_id =', options, constraints, params, errors);
	limit = generateResultLimit(options.limit, params, errors);

	if (errors.length) {
		throw errors;
	}

	let opt_string = '';
	if (constraints.length) opt_string = 'WHERE ';
	opt_string += constraints.join(' AND ');
	opt_string += limit;

	return db.execute(...schemas.channels_by_guild.getSelectStmt(opt_string, params))
		.then(res => res.rows)
		.then(rows => rows.map(convertTypesForDistribution))
	;
};

// returns or throws
const updateChannel = async (guild_snowflake, channel_snowflake, changes) => {
	const errors = [];

	if (guild_snowflake === undefined || guild_snowflake === null)
		errors.push(`A guild snowflake must be passed, but ${guild_snowflake} was supplied`);
	else guild_snowflake = coerceToLong(guild_snowflake, errors);
	if (channel_snowflake === undefined || channel_snowflake === null)
		errors.push(`A channel snowflake must be passed, but ${channel_snowflake} was supplied`);
	else channel_snowflake = coerceToLong(channel_snowflake, errors);
	if (changes === undefined || changes === null || changes.constructor.name !== 'Object' || Object.keys(changes).length < 1)
		errors.push(`An object describing changes to be made must be passed, but ${changes} was supplied`);
	if (errors.length) {
		throw errors;
	}

	return getChannels(guild_snowflake, {channel_id: channel_snowflake})
		.then(rows => rows.length > 0)
		.then(recordExists => {
			if (recordExists)
				return db.execute(...schemas.channels_by_guild.getUpdateStmt(Object.assign({}, {guild_id: guild_snowflake, channel_id: channel_snowflake}, changes)))
					.then(() => {})
			;
			else
				throw [`Only existing channels may be updated, but no channel with id ${channel_snowflake} was found in guild ${guild_snowflake}`];
		});
};

// returns or throws
const deleteChannel = async (guild_snowflake, channel_snowflake) => {
	const errors = [];
	if (guild_snowflake === undefined || guild_snowflake === null)
		errors.push(`A guild snowflake must be passed, but ${guild_snowflake} was supplied`);
	else guild_snowflake = coerceToLong(guild_snowflake, errors);
	if (channel_snowflake === undefined || channel_snowflake === null)
		errors.push(`A channel snowflake must be passed, but ${channel_snowflake} was supplied`);
	else channel_snowflake = coerceToLong(channel_snowflake, errors);
	if (errors.length) {
		throw errors;
	}

	return db.execute(...schemas.channels_by_guild.getDeleteStmt({
		guild_id: guild_snowflake
		, channel_id: channel_snowflake
	})).then(() => {});
};

const clearChannels = async (guild_snowflake) => {
	const errors = [];
	if (guild_snowflake === undefined || guild_snowflake === null)
		errors.push(`A guild snowflake must be passed, but ${guild_snowflake} was supplied`);
	else guild_snowflake = coerceToLong(guild_snowflake, errors);
	if (errors.length) {
		throw errors;
	}

	return db.execute('DELETE FROM channels_by_guild WHERE guild_id = ?', [guild_snowflake], { prepare: true }).then(() => {});
};


/*************************************************************************
 * messages_by_channel
 */
// returns description of message, or throws
const createMessage = async (channel_snowflake, author_snowflake, body) => {
	const errors = [];
	if (channel_snowflake === undefined || channel_snowflake === null)
		errors.push(`A channel snowflake must be passed, but ${channel_snowflake} was supplied`);
	else channel_snowflake = coerceToLong(channel_snowflake, errors);
	if (author_snowflake === undefined || author_snowflake === null)
		errors.push(`A user snowflake must be passed, but ${author_snowflake} was supplied`);
	else author_snowflake = coerceToLong(author_snowflake, errors);
	if (body === undefined || body === null)
		errors.push(`A body must be passed, but ${body} was supplied`);
	if (errors.length) {
		throw errors;
	}

	const message_id = coerceToLong(snowmachine.generate().snowflake);

	const record = {
		channel_id: channel_snowflake
		, bucket: getBucket(message_id)
		, author_id: author_snowflake
		, message_id
		, body
	};

	return db.execute(...schemas.messages_by_channel_bucket.getInsertStmt(record))
		.then(() => convertTypesForDistribution(record));
};

// returns list of message descriptions, or throws
// do not depend on the output to be sorted in any manner
// FIXME ok so if you have two buckets and all of the messages are in range and you request just enough to get one and a half buckets,
// how do you ensure that you get the right half of the second bucket
// FIXME FIXME FIXME ohno ^
// you might need to grab the whole bucket and filter over here
// FIXME unrelated, if they give us a message_id, just search the bucket it belongs in! brilliant!
const getMessages = async (channel_snowflake, options = {
	before: undefined
	, after: undefined
	, message_id: undefined
	, limit: undefined
}) => {
	const keys = Object.keys(options);
	// these are the partition keys; we'll need them for sure. put the bucket in a predictable location (0) so we can swap it out later
	const constraints = ['bucket = ?', 'channel_id = ?'];
	const params = [null, channel_snowflake];
	const errors = [];

	// validate types of surface-level parameters
	if (channel_snowflake === undefined || channel_snowflake === null)
		errors.push(`A channel snowflake must be passed, but ${channel_snowflake} was supplied`);
	else channel_snowflake = coerceToLong(channel_snowflake, errors);
	if (options === null || options.constructor.name !== 'Object')
		errors.push(`An object containing filtering keys was expected, but ${options} was supplied`);
	if (errors.length) {
		throw errors;
	}
	// we now certainly have a channel_snowflake and an options object
	// next let's ensure that all options are either undefined or of a correct type
	if (options.before !== undefined)
		options.before = coerceToLong(options.before, errors);
	if (options.after !== undefined)
		options.after = coerceToLong(options.after, errors);
	if (options.message_id !== undefined)
		options.message_id = coerceToLong(options.message_id, errors);
	if (options.limit !== undefined) {
		if (options.limit === null) {
			errors.push(`'limit' search parameter is expected to be a Number, but ${options.limit} was supplied`);
		} else if (options.limit.constructor.name !== 'Number') {
			errors.push(`'limit' search parameter is expected to be a Number, but ${options.limit} of type ${options.limit.constructor.name} was supplied`);
		}
	}
	if (errors.length) {
		throw errors;
	}
	// we now certainly know:
	// - channel_snowflake is a Long
	// - options is an object
	// - options.before is either a Long or undefined
	// - options.after is either a Long or undefined
	// - options.message_id is either a Long or undefined
	// - options.limit is either a number or undefined
	// next let's verify that we have at least one of message_id and limit
	if (options.message_id !== undefined) {
		options.limit = 1;
		constraints.push('message_id = ?');
		params.push(options.message_id);
	} else if (options.limit === undefined) {
		errors.push(`One of 'message_id' or 'limit' must be specified in the search options object, but neither was supplied`);
	}
	// we now certainly know:
	// - all of the above items
	// - we have a limit
	// - if we're looking for a specific message, we've got that constraint listed
	// next let's determine which direction to search:
	// - if there's a before, then we search backward
	// - otherwise, if there's an after, then we search forward
	// - otherwise, we search backward
	// we'll add this value to our bucket to move through time: +1 means a later bucket (forward); -1 means an earlier bucket (backward)
	//           before    is less than    after
	// earlier <---|-------------------------|---> later
	//     backward                           forward
	//        -1                                 +1
	// i sure hope this helps me or i'm gonna look real dumb
	let search_direction = -1; // backward is the default
	if (options.before === undefined && options.after !== undefined) { // but if this is the case, we go forward instead
		search_direction = 1; // credit to Ryan Unroe
	}
	// we now certainly know:
	// - all of the above items
	// - which way we're traveling through time
	// next let's ensure that our start and end times are both defined and reasonable
	const now = coerceToLong(snowmachine.generate().snowflake);
	const dawn = channel_snowflake;
	if (!options.before || options.before.lessThan(dawn))
		options.before = dawn;
	if (!options.after || options.after.greaterThan(now))
		options.after = now;
	if (options.before.greaterThan(options.after))
		errors.push(`The 'before' timestamp (${options.before}) occurs after the 'after' timestamp (${options.after}), which is an impossible scenario`);
	// we now certainly know:
	// - all of the above items
	// - our before and after times are defined and reasonable
	// next let's add them to our list of constraints
	constraints.push('message_id >= ?');
	params.push(options.before);
	constraints.push('message_id <= ?');
	params.push(options.after);
	// we now certainly know:
	// - all of the above items
	// - we will only receive messages from within the time boundaries
	// next let's determine our earliest, latest, and starting buckets
	const earliest_bucket = getBucket(options.after, errors);
	const latest_bucket = getBucket(options.before, errors);
	const starting_bucket = search_direction == 1 ? earliest_bucket : latest_bucket;
	// this was the last opportunity for pre-database errors to be pushed, so let's flush them out one last time
	if (errors.length) {
		throw errors;
	}
	// we now certainly know:
	// - all of the above items
	// - the bucket we're starting in
	// - the buckets to stay between (inclusive)
	// next let's define our query string
	const query = 'SELECT * FROM messages_by_channel_bucket WHERE ' + constraints.join(' AND ') + ' LIMIT ?;';
	// we still haven't pushed the limit, so let's do that now
	params.push(options.limit);
	// Q: this is a limit on how many messages we want total, right? not how many we want per bucket? so why include it?
	// A: that's a great question! while we may have to scan more than one bucket, we still won't ever want more than n messages
	//    from a single bucket, so it's okay to include this. it helps in the case that we find all of our messages in one bucket,
	//    and it doesn't hurt very much if we have to scan multiple buckets anyways. that's assuming Cassandra works the way I imagine
	//    it does, which it may not. I'm hoping that it just stops scanning when we reach the limit of the query. I also hope, but less so,
	//    that it ignores the limit if it's greater than the number of rows in a table.
	// Q: hang on a sec. if you find some messages in one bucket, then go on to the next bucket, wouldn't it make sense to reduce the query
	//    limit from then on?
	// A: ...yes it would! let's do that!
	// take note, ye intrepid reader! the limit shall henceforth be specially-located at the _end_ of the params array, so we can push and pop it
	// when we want to change it. we'll do this whenever we get some messages back.

	// keep in mind that the bucket and channel_id were in the params and constraints arrays to start with.
	// we'll overwrite the bucket (at index 0) each loop, and we'll overwrite the result limit (at last index) whenever we find messages
	// we now certainly know:
	// - all of the above items
	// - the query we intend to execute
	// - the parameters to pass in
	// next we'll execute queries until we have enough messages to satisfy the limit, or until we run out of buckets, whichever comes first
	const messages = []; // here we'll accumulate messages that match the criteria
	let bucket = starting_bucket;
	//logger.debug(query);
	//logger.debug(`Searching buckets ${earliest_bucket} to ${latest_bucket}, starting with ${starting_bucket}`);
	while (earliest_bucket <= bucket && bucket <= latest_bucket && options.limit > 0) { // options.limit will decrease as we gather messages
		params[0] = bucket;
		//logger.debug('Bucket: ' + bucket);
		//console.log(params.map(param => param.toString()));
		new_messages = await db.execute(query, params, { prepare: true }).catch(error => errors.push(error));
		// so yeah. it's possible that the db will throw an error somehow, still...idk how but i'd rather be prepared-ish
		// so if we see an error, we'll happily forward it on to the unsuspecting caller, who will now know about our database's
		// internals and not really have a clue how to fix the problem probably. yeah. sounds good
		if (errors.length) {
			throw errors;
		}
		messages.push(...new_messages);
		options.limit -= new_messages.length; // yeah, i think that was a pretty good idea! good job, question-asker
		params.pop();
		params.push(options.limit);
	}
	// so by now we've either gathered enough messages or checked all the buckets in our time frame
	// let's blow this popsicle stand
	return messages;
};

// returns or throws
const updateMessage = async (channel_snowflake, message_snowflake, changes) => {
	const errors = [];

	if (channel_snowflake === undefined || channel_snowflake === null)
		errors.push(`A channel snowflake must be passed, but ${channel_snowflake} was supplied`);
	else channel_snowflake = coerceToLong(channel_snowflake, errors);
	if (message_snowflake === undefined || message_snowflake === null)
		errors.push(`A message snowflake must be passed, but ${message_snowflake} was supplied`);
	else message_snowflake = coerceToLong(message_snowflake, errors);
	if (changes === undefined || changes === null || changes.constructor.name !== 'Object' || Object.keys(changes).length < 1)
		errors.push(`An object describing changes to be made must be passed, but ${changes} was supplied`);
	if (errors.length) {
		throw errors;
	}

	return getMessages(channel_snowflake, {message_id: message_snowflake})
		.then(rows => rows.length > 0)
		.then(recordExists => {
			if (recordExists)
				return db.execute(...schemas.messages_by_channel_bucket.getUpdateStmt(Object.assign({}, {channel_id: channel_snowflake, message_id: message_snowflake}, changes)))
					.then(() => {})
			;
			else
				throw [`Only existing messages may be updated, but no message with id ${message_snowflake} was found in channel ${channel_snowflake}`];
		});
};

// returns or throws
const deleteMessage = async (channel_snowflake, message_snowflake) => {
	const errors = [];
	if (channel_snowflake === undefined || channel_snowflake === null)
		errors.push(`A channel snowflake must be passed, but ${channel_snowflake} was supplied`);
	else channel_snowflake = coerceToLong(channel_snowflake, errors);
	if (message_snowflake === undefined || message_snowflake === null)
		errors.push(`A message snowflake must be passed, but ${message_snowflake} was supplied`);
	else message_snowflake = coerceToLong(message_snowflake, errors);
	if (errors.length) {
		throw errors;
	}

	return db.execute(...schemas.messages_by_channel_bucket.getDeleteStmt({
		channel_id: channel_snowflake
		, message_id: message_snowflake
	})).then(() => {});
};

/*************************************************************************
 * users
 */
// returns description of user, or throws
const createUser = async (name, email, password, icon_snowflake) => {
	const errors = [];
	if (name === undefined || name === null)
		errors.push(`A name must be passed, but ${name} was supplied`);
	if (email === undefined || email === null)
		errors.push(`A email must be passed, but ${email} was supplied`);
	if (password === undefined || password === null)
		errors.push(`A password must be passed, but ${password} was supplied`);
	if (icon_snowflake === undefined || icon_snowflake === null)
		errors.push(`An icon snowflake must be passed, but ${icon_snowflake} was supplied`);
	else icon_snowflake = coerceToLong(icon_snowflake, errors);
	if (errors.length) {
		throw errors;
	}

	// TODO validate email using Schema::validators
	// TODO ^ Consider secondary index on emails to allow filtering by equality/fast check whether email is taken
	const used_discrims = await getUsers({name}).then(users => users.map(user => user.discriminator));
	if (used_discrims.length >= discriminator_cap)
		throw [`Too many users already have the name ${name}; please choose another name`];
	let discriminator = Math.round(Math.random()*10000);
	do {
		discriminator += 1;
		discriminator %= 10000;
	} while (used_discrims.includes(discriminator));

	// FIXME what errors can this throw? how should we handle them?
	return hasher.hash(password, hash_options)
		.catch(e => {
			logger.error(e);
			throw ['An error occurred in the process of hashing the supplied password. Please report this error to the developers, along with this number: ' + snowmachine.generate().snowflake];
		}) // use the number as a timestamp to find out when the thing happened. not very useful since none of the information is timestamped... TODO add timestamps to logger
		.then(hash => {

			const record = {
				user_id: coerceToLong(snowmachine.generate().snowflake)
				, discriminator
				, name
				, email
				, password: hash
				, icon_id: icon_snowflake
			};

			return db.execute(...schemas.users.getInsertStmt(record))
				.then(() => convertTypesForDistribution(record))
			;
		});
};

// returns list of user descriptions, or throws
const getUsers = async (options = {
	user_id: undefined
	, limit: undefined
}) => {
	const keys = Object.keys(options);
	const constraints = [];
	let limit = '';
	const params = [];
	const errors = [];

	// catch passing other junk as the options
	if (options === null || options.constructor.name !== 'Object') 
		errors.push(`An optional object containing filtering keys was expected, but ${options} was supplied`);

	addSnowflakeConstraint('user_id', 'user_id =', options, constraints, params, errors);
	limit = generateResultLimit(options.limit, params, errors);

	if (errors.length) {
		throw errors;
	}

	let opt_string = '';
	if (constraints.length) opt_string = 'WHERE ';
	opt_string += constraints.join(' AND ');
	opt_string += limit;

	// FIXME don't leak hashes! ever! what does that mean? dunno. make up your mind
	return db.execute(...schemas.users.getSelectStmt(opt_string, params))
		.then(res => res.rows)
		.then(rows => rows.map(row => { delete row.password; return row; }))
		.then(rows => rows.map(convertTypesForDistribution))
	;
};

// returns or throws
// FIXME require the user to supply their password, at least if they're changing their password. could just require for any change
// FIXME automatically change discriminator if necessary
const updateUser = async (user_snowflake, changes) => {
	const errors = [];

	if (user_snowflake === undefined || user_snowflake === null)
		errors.push(`A user snowflake must be passed, but ${user_snowflake} was supplied`);
	else user_snowflake = coerceToLong(user_snowflake, errors);
	if (changes === undefined || changes === null || changes.constructor.name !== 'Object' || Object.keys(changes).length < 1)
		errors.push(`An object describing changes to be made must be passed, but ${changes} was supplied`);
	if (changes && changes.icon_id !== undefined)
		changes.icon_id = coerceToLong(changes.icon_id, errors);

	if (errors.length) {
		throw errors;
	}

	return getUsers({user_id: user_snowflake})
		.then(rows => rows.length > 0)
		.then(recordExists => {
			if (recordExists)
				return db.execute(...schemas.users.getUpdateStmt(Object.assign({}, {user_id: user_snowflake}, changes)))
					.then(() => {})
			;
			else
				throw [`Only existing users may be updated, but no user with id ${user_snowflake} was found`];
		});
};

// returns or throws
const deleteUser = async (user_snowflake) => {
	const errors = [];
	if (user_snowflake === undefined || user_snowflake === null)
		errors.push(`A user snowflake must be passed, but ${user_snowflake} was supplied`);
	else user_snowflake = coerceToLong(user_snowflake, errors);
	if (errors.length) {
		throw errors;
	}

	return db.execute(...schemas.users.getDeleteStmt({
		user_id: user_snowflake
	})).then(() => {});
};

// returns a stringified snowflake or null, always---never throws
const authenticate = async (email, password) => {
	return db.execute('SELECT user_id, password FROM users WHERE email = ?;', [email], { prepare: true })
		//.then(res => { console.log('Response', res); return res; })
		.then(res => res.rows[0])
		.then(async pair => {
			if (await hasher.verify(pair.password, password))
				return pair.user_id.toString();
			return null;
		})
		.catch(() => null);
		//.catch((e) => {console.log(e); return null;});
};

/*************************************************************************
 * icons
 */
// returns description of user, or throws
const createIcon = async (url) => {
	const errors = [];
	// FIXME validate URL
	if (url === undefined || url === null)
		errors.push(`A url must be passed, but ${url} was supplied`);
	if (errors.length) {
		throw errors;
	}

	const record = {
		icon_id: coerceToLong(snowmachine.generate().snowflake)
		, url
	};

	return db.execute(...schemas.icons.getInsertStmt(record))
		.then(() => convertTypesForDistribution(record))
	;
};

const getIcon  = async (icon_id) => {
	const errors = [];
	icon_id = coerceToLong(icon_id, errors);

	if (errors.length) {
		throw errors;
	}

	return db.execute('SELECT * FROM icons WHERE icon_id = ?', [icon_id], { prepare: true })
		.then(res => res.rows)
		.then(rows => convertTypesForDistribution(rows[0]))
		.catch(e => null);
	;
};

// TODO add userExists, guildExists, etc.
// returns list of user descriptions, or throws
const iconExists = async (icon_id) => {
	const errors = [];
	icon_id = coerceToLong(icon_id, errors);

	if (errors.length) {
		throw errors;
	}

	return db.execute('SELECT * FROM icons WHERE icon_id = ?', [icon_id], { prepare: true })
		.then(res => res.rows.length > 0)
	;
};

const executeRaw = async (stmt, params) => {
	return db.execute(stmt, params, { prepare: true });
};

// [{query: '', params: []}]
const executeBatch = async (stmts) => {
	return db.batch(stmts, { prepare: true });
};

module.exports = {
	Schema, schemas, executeRaw, executeBatch
	, createGuild, getGuilds, updateGuild, deleteGuild
	, createChannel, getChannels, updateChannel, deleteChannel, clearChannels, addChannelToGuild // FIXME that last one doesn't work yet
	, createMessage, getMessages, updateMessage, deleteMessage
	, createUser, getUsers, updateUser, deleteUser, authenticate
	, createIcon, getIcon, iconExists
};
